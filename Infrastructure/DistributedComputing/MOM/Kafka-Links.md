[![返回目录](https://user-images.githubusercontent.com/5803001/38079637-ff0abcf0-3371-11e8-9b76-ad651620afc7.jpg)](https://github.com/wxyyxc1992/Awesome-Links)

# Kafka Links

- [Kafka 实战 —— 简单实例](http://www.cnblogs.com/smartloli/p/4543211.html?spm=5176.100239.blogcont33922.3.lS3TVC)

* [2017-Apache Kafka Goes 1.0](https://www.confluent.io/blog/apache-kafka-goes-1-0/): The feature set and the broad deployments all speak of a stable and Enterprise-ready product, which leads to an important step we are taking with this release: as of today, Apache Kafka is going 1.0!

* [2017-View Counting at Reddit](https://parg.co/bJE): Reddit’s data pipeline is primarily oriented around Apache Kafka. When a user views a post, an event gets fired and sent to an event collector server, which batches the events and persists them into Kafka.

* [Kafka 设计解析(六)- Kafka 高性能架构之道](http://www.jasongj.com/kafka/high_throughput/)

* [Benchmarking Kafka Performance #Series#](https://hackernoon.com/benchmarking-kafka-performance-part-1-write-throughput-7c7a76ab7db1)：a series that explores Kafka performance on multiple public cloud providers. [Part 1: Write Throughput](https://hackernoon.com/benchmarking-kafka-performance-part-1-write-throughput-7c7a76ab7db1)

* [Kafka 深度解析](http://www.jasongj.com/2015/01/02/Kafka%e6%b7%b1%e5%ba%a6%e8%a7%a3%e6%9e%90/)

* [Kafka 源码分析](https://zqhxuyuan1.gitbooks.io/kafka/content/chapter1-intro.html)

* [Kafka 技术内幕系列博客](http://zqhxuyuan.github.io/2017/01/01/Kafka-Code-Index/)

- [Awesome Kafka](https://github.com/infoslack/awesome-kafka#books)

- [2017-Exactly-once Semantics are Possible: Here’s How Kafka Does it](https://parg.co/bXj): In this post, I’d like to tell you what exactly-once semantics mean in Apache Kafka, why it is a hard problem, and how the new idempotence and transactions features in Kafka enable correct exactly-once stream processing using Kafka’s Streams API.

- [2017-Delivering Billions of Messages Exactly Once](https://segment.com/blog/exactly-once-delivery/):In the past three months we’ve built an entirely new de-duplication system to get as close as possible to exactly-once delivery, in the face of a wide variety of failure modes. The new system is able to track 100x the number of messages of the old system, with increased reliability, at a fraction of the cost. Here’s how.
